{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2095,
     "status": "ok",
     "timestamp": 1676034064537,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "4K-VUNVUXV5N",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zTMT5l_bW4V"
   },
   "source": [
    "# 1. Chargement de la base de données `Iris.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 924
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1676034064539,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "XFXgLn_NXge1",
    "outputId": "a77bef47-afff-49c4-8ade-d676b338d34f"
   },
   "outputs": [],
   "source": [
    "irisDataframe = pd.read_csv(\"iris.txt\", sep=\"\\t\", header=None)\n",
    "display(irisDataframe)\n",
    "X = irisDataframe.iloc[:, :4]\n",
    "print(X)\n",
    "y = irisDataframe.iloc[:, 4:5]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0NYHIZobjyZ"
   },
   "source": [
    "# 2. Découpage de la base en Apprentissage/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1676034068499,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "uW4qmZ1VYEDI"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eOCrcsKbpND"
   },
   "source": [
    "# 3. Implémentation d’un Perceptron Multi-classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1676049147385,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "ZKL2aiIfbU_I"
   },
   "outputs": [],
   "source": [
    "class PerceptronMultiClasse():\n",
    "\n",
    "  def __init__(self, X, y, step=0.1, max_iter=1000):\n",
    "    print(\"Setup Multi-class Perceptron\")\n",
    "    \n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.classes = np.unique(y)\n",
    "    self.step = step\n",
    "    self.max_iter = max_iter\n",
    "    self.W = np.random.rand(len(self.classes), len(self.X.axes[1]))\n",
    "\n",
    "    print(f\"Input : \\n{self.X}\")\n",
    "    print(f\"Classes : {self.classes}\")\n",
    "    \n",
    "    print(f\"Initial weights : {self.W} \\n\")\n",
    "\n",
    "  def train(self):\n",
    "    print(f\"Start training\")\n",
    "    print(f\"y : {self.y}\")\n",
    "\n",
    "    stable = False\n",
    "    currentStep = 0\n",
    "    while not stable and currentStep < self.max_iter:\n",
    "      stable = True\n",
    "      Cj = 0\n",
    "      for i in range(len(self.X)):\n",
    "        # print(f\"i : {i} \\n\")\n",
    "        x = self.X.values[i]\n",
    "        # print(f\"x : {x} \\n\")\n",
    "        Ci = (self.y.values - 1)[i]\n",
    "        y_training = []\n",
    "        for k in range(len(self.classes)):\n",
    "          y_training.append(np.dot(self.W[k], x))\n",
    "        Cj = np.argmax(y_training)\n",
    "        # print(f\"Ci : {Ci} - Cj : {Cj}\")\n",
    "        if Ci != Cj:\n",
    "          self.W[Ci] = self.W[Ci] + (self.step) * x\n",
    "          self.W[Cj] = self.W[Cj] - (self.step) * x\n",
    "          stable = False\n",
    "      currentStep+=1\n",
    "\n",
    "    print(f\"Trained weigths : {self.W}\")\n",
    "\n",
    "  def prediction(self, x):\n",
    "    # print(x)\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(len(self.classes)):\n",
    "      y_pred.append(np.dot(self.W[i], x))\n",
    "      \n",
    "    # print(y_pred)\n",
    "    return np.argmax(y_pred) + 1\n",
    "\n",
    "  def evaluate(self, X_test, y_test):\n",
    "    print(f\"Start evaluation\")\n",
    "\n",
    "    print(f\"X test : {np.shape(X_test)}\")\n",
    "    \n",
    "    y_pred = pd.concat([pd.DataFrame([self.prediction(X_test.values[i])]) for i in range(len(X_test.axes[0]))], ignore_index=True)\n",
    "    result_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    score = f1_score(y_test, y_pred, average=None)\n",
    "    precision = precision_score(y_test, y_pred, average=None)\n",
    "    recall = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "    print(f\"y pred : {np.shape(y_pred)}, {np.unique(y_pred)}\")\n",
    "    print(f\"y test : {np.shape(y_test)}, {np.unique(y_test)}\")\n",
    "    print(result_conf_matrix)\n",
    "\n",
    "    print(f\"F1 score : {score}\")\n",
    "    print(f\"Precision : {precision}\")\n",
    "    print(f\"Rappel : {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDu-RLd75pMO"
   },
   "source": [
    "# 4. Évaluation des performances du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6369,
     "status": "ok",
     "timestamp": 1676049155593,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "xkenVniii45l",
    "outputId": "30ce06fd-ba70-4de2-9c7d-95d5135e5657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Multi-class Perceptron\n",
      "Input : \n",
      "       0    1    2    3\n",
      "96   5.7  2.9  4.2  1.3\n",
      "105  7.6  3.0  6.6  2.1\n",
      "66   5.6  3.0  4.5  1.5\n",
      "0    5.1  3.5  1.4  0.2\n",
      "122  7.7  2.8  6.7  2.0\n",
      "..   ...  ...  ...  ...\n",
      "71   6.1  2.8  4.0  1.3\n",
      "106  4.9  2.5  4.5  1.7\n",
      "14   5.8  4.0  1.2  0.2\n",
      "92   5.8  2.6  4.0  1.2\n",
      "102  7.1  3.0  5.9  2.1\n",
      "\n",
      "[100 rows x 4 columns]\n",
      "Classes : [1 2 3]\n",
      "Initial weights : [[0.49195772 0.00134452 0.6121464  0.35942495]\n",
      " [0.78077341 0.43711902 0.96833044 0.9039306 ]\n",
      " [0.26468469 0.85151942 0.06652709 0.51756701]] \n",
      "\n",
      "Start training\n",
      "y :      4\n",
      "96   2\n",
      "105  3\n",
      "66   2\n",
      "0    1\n",
      "122  3\n",
      "..  ..\n",
      "71   2\n",
      "106  3\n",
      "14   1\n",
      "92   2\n",
      "102  3\n",
      "\n",
      "[100 rows x 1 columns]\n",
      "Trained weigths : [[  8.64195772  14.75134452 -16.8578536   -8.04057505]\n",
      " [  6.60077341  10.24711902  -7.56166956 -14.0760694 ]\n",
      " [-13.70531531 -23.70848058  26.06652709  23.89756701]]\n",
      "Start evaluation\n",
      "X test : (50, 4)\n",
      "y pred : (50, 1), [1 2 3]\n",
      "y test : (50, 1), [1 2 3]\n",
      "[[19  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  0 16]]\n",
      "F1 score : [1.         0.96551724 0.96969697]\n",
      "Precision : [1.         1.         0.94117647]\n",
      "Rappel : [1.         0.93333333 1.        ]\n"
     ]
    }
   ],
   "source": [
    "multi_classe = PerceptronMultiClasse(X_train, y_train, 0.1)\n",
    "multi_classe.train()\n",
    "multi_classe.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QK-seKY95eIh"
   },
   "source": [
    "# 5. Implémentation d’un Percepron Multi-couches (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1676053383979,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "ux1WWv6VPFWy"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def evaluate(y_pred, y_test):\n",
    "    print(f\"Start evaluation\")\n",
    "\n",
    "    result_conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    score = f1_score(y_test, y_pred, average=None)\n",
    "    precision = precision_score(y_test, y_pred, average=None)\n",
    "    recall = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "    print(f\"General Accuracy {accuracy_score(y_true=y_test, y_pred=y_pred)*100}% \")\n",
    "\n",
    "    print(f\"y pred : {np.shape(y_pred)}, {np.unique(y_pred)}\")\n",
    "    print(f\"y test : {np.shape(y_test)}, {np.unique(y_test)}\")\n",
    "    print(result_conf_matrix)\n",
    "\n",
    "    print(f\"F1 score : {score}\")\n",
    "    print(f\"Precision : {precision}\")\n",
    "    print(f\"Rappel : {recall}\")\n",
    "\n",
    "def analyse(filename=\"iris.txt\") :\n",
    "  dataframe = pd.read_csv(f\"./{filename}\", delim_whitespace=True, header=None)\n",
    "\n",
    "  X = dataframe.iloc[:,:-1].values\n",
    "  Y = dataframe.iloc[:, -1].values\n",
    "\n",
    "  nbClasses = len(np.unique(Y))\n",
    "  input_size = len(X[0])\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 1/3, random_state = 1)\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(X_train)\n",
    "  X_train_norm = scaler.transform(X_train)\n",
    "  X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "  print(f\"\\n\\n{filename} MLPClassifier\")\n",
    "  MLP = MLPClassifier(random_state=1)\n",
    "  MLP.fit(X_train, Y_train)\n",
    "  y_MLP = MLP.predict(X_test)\n",
    "  evaluate(y_MLP, Y_test)\n",
    "  print(f\"\\n\\n{filename} MLPClassifier Normalized\")\n",
    "  MLP = MLPClassifier(random_state=1)\n",
    "  MLP.fit(X_train_norm, Y_train)\n",
    "  y_MLP = MLP.predict(X_test_norm)\n",
    "  evaluate(y_MLP, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHHuW5M1538D"
   },
   "source": [
    "# 6. Évaluation des performances du modèle MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvHEPRP8awvj"
   },
   "source": [
    "## → Établir les prédictions sur les données de la base de test T."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOKTLjzea0qN"
   },
   "source": [
    "## → Écrire un programme pour calculer la matrice de confusion, l’Accuracy globale, la précision et le rappel pour chaque classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4miOzHcLa4mv"
   },
   "source": [
    "## → Les réseaux de neurones apprennent mieux si les données sont préalablement normalisées, c’est à dire si on a pris soin que la variance des valeurs soit la même pour tous les descripteurs. Il faut bien sûr veiller à ce que cette même normalisation soit appliquée aux données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9t4-2P5bKH_"
   },
   "source": [
    "## → Une comparaison entre normalisation/sans normalisation serait la bienvenue !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 746,
     "status": "ok",
     "timestamp": 1676053386706,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "HusXAYj357Ch",
    "outputId": "ce02f584-4501-493f-9e26-8822359ac7b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "iris.txt MLPClassifier\n",
      "Start evaluation\n",
      "General Accuracy 92.0% \n",
      "y pred : (50,), [1 2 3]\n",
      "y test : (50,), [1 2 3]\n",
      "[[17  0  0]\n",
      " [ 0 15  4]\n",
      " [ 0  0 14]]\n",
      "F1 score : [1.         0.88235294 0.875     ]\n",
      "Precision : [1.         1.         0.77777778]\n",
      "Rappel : [1.         0.78947368 1.        ]\n",
      "\n",
      "\n",
      "iris.txt MLPClassifier Normalized\n",
      "Start evaluation\n",
      "General Accuracy 96.0% \n",
      "y pred : (50,), [1 2 3]\n",
      "y test : (50,), [1 2 3]\n",
      "[[17  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  1 13]]\n",
      "F1 score : [1.         0.94736842 0.92857143]\n",
      "Precision : [1.         0.94736842 0.92857143]\n",
      "Rappel : [1.         0.94736842 0.92857143]\n"
     ]
    }
   ],
   "source": [
    "analyse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWtP8WcBbO4O"
   },
   "source": [
    "## → Ré-appliquer toute la chaine de traitement sur les bases : (glass.txt, breast-cancer-wisconsin.txt, Lsun.txt et Wave) disponibles sur Claroline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pACJdbV7UpbY"
   },
   "source": [
    "## glass.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 672,
     "status": "ok",
     "timestamp": 1676053406829,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "NBk3XnZrbWPt",
    "outputId": "7b41d29b-a8a2-4998-8a6b-3b159319c765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "glass.txt MLPClassifier\n",
      "Start evaluation\n",
      "General Accuracy 30.555555555555557% \n",
      "y pred : (72,), [2]\n",
      "y test : (72,), [1 2 3 5 6 7]\n",
      "[[ 0 28  0  0  0  0]\n",
      " [ 0 22  0  0  0  0]\n",
      " [ 0  7  0  0  0  0]\n",
      " [ 0  3  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0 10  0  0  0  0]]\n",
      "F1 score : [0.         0.46808511 0.         0.         0.         0.        ]\n",
      "Precision : [0.         0.30555556 0.         0.         0.         0.        ]\n",
      "Rappel : [0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "\n",
      "glass.txt MLPClassifier Normalized\n",
      "Start evaluation\n",
      "General Accuracy 72.22222222222221% \n",
      "y pred : (72,), [1 2 5 6 7]\n",
      "y test : (72,), [1 2 3 5 6 7]\n",
      "[[23  5  0  0  0  0]\n",
      " [ 2 18  0  1  1  0]\n",
      " [ 2  5  0  0  0  0]\n",
      " [ 0  2  0  1  0  0]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 1  1  0  0  0  8]]\n",
      "F1 score : [0.82142857 0.67924528 0.         0.4        0.8        0.88888889]\n",
      "Precision : [0.82142857 0.58064516 0.         0.5        0.66666667 1.        ]\n",
      "Rappel : [0.82142857 0.81818182 0.         0.33333333 1.         0.8       ]\n"
     ]
    }
   ],
   "source": [
    "analyse(\"glass.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N67TnDI_Uv1Q"
   },
   "source": [
    "## breast-cancer-wisconsin.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2989,
     "status": "ok",
     "timestamp": 1676053411639,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "wdNfa4eaU0l1",
    "outputId": "1ff5ada3-4ac2-467a-ac55-6464bef369fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "breast-cancer-wisconsin.txt MLPClassifier\n",
      "Start evaluation\n",
      "General Accuracy 96.13733905579399% \n",
      "y pred : (233,), [1 2]\n",
      "y test : (233,), [1 2]\n",
      "[[153   2]\n",
      " [  7  71]]\n",
      "F1 score : [0.97142857 0.94039735]\n",
      "Precision : [0.95625    0.97260274]\n",
      "Rappel : [0.98709677 0.91025641]\n",
      "\n",
      "\n",
      "breast-cancer-wisconsin.txt MLPClassifier Normalized\n",
      "Start evaluation\n",
      "General Accuracy 98.71244635193133% \n",
      "y pred : (233,), [1 2]\n",
      "y test : (233,), [1 2]\n",
      "[[153   2]\n",
      " [  1  77]]\n",
      "F1 score : [0.99029126 0.98089172]\n",
      "Precision : [0.99350649 0.97468354]\n",
      "Rappel : [0.98709677 0.98717949]\n"
     ]
    }
   ],
   "source": [
    "analyse(\"breast-cancer-wisconsin.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqVj94SLU4Rq"
   },
   "source": [
    "## Lsun.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1676053420600,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "1yFywT4XU4gh",
    "outputId": "e514c37f-6919-4409-f673-d9e9f97cbb25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Lsun.txt MLPClassifier\n",
      "Start evaluation\n",
      "General Accuracy 100.0% \n",
      "y pred : (134,), [1 2 3]\n",
      "y test : (134,), [1 2 3]\n",
      "[[57  0  0]\n",
      " [ 0 38  0]\n",
      " [ 0  0 39]]\n",
      "F1 score : [1. 1. 1.]\n",
      "Precision : [1. 1. 1.]\n",
      "Rappel : [1. 1. 1.]\n",
      "\n",
      "\n",
      "Lsun.txt MLPClassifier Normalized\n",
      "Start evaluation\n",
      "General Accuracy 100.0% \n",
      "y pred : (134,), [1 2 3]\n",
      "y test : (134,), [1 2 3]\n",
      "[[57  0  0]\n",
      " [ 0 38  0]\n",
      " [ 0  0 39]]\n",
      "F1 score : [1. 1. 1.]\n",
      "Precision : [1. 1. 1.]\n",
      "Rappel : [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "analyse(\"Lsun.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWdzolpgU6eM"
   },
   "source": [
    "## Wave.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13319,
     "status": "ok",
     "timestamp": 1676053437999,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "u0wLTRKCU6tY",
    "outputId": "da43bd2b-9df9-4839-d211-63287c41a35d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Wave.txt MLPClassifier\n",
      "Start evaluation\n",
      "General Accuracy 83.0233953209358% \n",
      "y pred : (1667,), [0 1 2]\n",
      "y test : (1667,), [0 1 2]\n",
      "[[456  37  45]\n",
      " [ 61 463  34]\n",
      " [ 66  40 465]]\n",
      "F1 score : [0.81355932 0.84335155 0.83408072]\n",
      "Precision : [0.78216123 0.85740741 0.85477941]\n",
      "Rappel : [0.84758364 0.8297491  0.81436077]\n",
      "\n",
      "\n",
      "Wave.txt MLPClassifier Normalized\n",
      "Start evaluation\n",
      "General Accuracy 83.62327534493102% \n",
      "y pred : (1667,), [0 1 2]\n",
      "y test : (1667,), [0 1 2]\n",
      "[[449  46  43]\n",
      " [ 57 463  38]\n",
      " [ 57  32 482]]\n",
      "F1 score : [0.81562216 0.84258417 0.85008818]\n",
      "Precision : [0.79751332 0.85582255 0.85612789]\n",
      "Rappel : [0.83457249 0.8297491  0.8441331 ]\n"
     ]
    }
   ],
   "source": [
    "analyse(\"Wave.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyCYOv_Q59Xp"
   },
   "source": [
    "# 7. Bagging de réseaux de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1676065834686,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "ASziXLM05-41"
   },
   "outputs": [],
   "source": [
    "class Bagging():\n",
    "  def __init__(self, X : pd.DataFrame, Y : pd.DataFrame, nb_sample : int = 10, clasifiers = [MLPClassifier(random_state=1)], normalized=True):\n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "    self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(X, Y, test_size = 1/3, random_state = 1)\n",
    "    self.X_samples = []\n",
    "    self.Y_samples = []\n",
    "    self.Y_predicts = []\n",
    "    self.Y_aggregated_predicts = []\n",
    "\n",
    "    self.X_train_norm = None\n",
    "    self.X_test_norm = None\n",
    "    self.normalized = normalized\n",
    "\n",
    "    if normalized:\n",
    "      scaler = StandardScaler()\n",
    "      scaler.fit(self.x_train)\n",
    "      self.X_train_norm = scaler.transform(self.x_train)\n",
    "      self.X_test_norm = scaler.transform(self.x_test)\n",
    "\n",
    "    for i in range(nb_sample):\n",
    "      self.add_sample()\n",
    "    self.clasifiers = clasifiers\n",
    "    self.trained_clasifiers = []\n",
    "\n",
    "  def add_sample(self):\n",
    "    new_x_sample = []\n",
    "    new_y_sample = []\n",
    "    for i in range(len(self.x_train)):\n",
    "      rand_index = np.random.randint(len(self.x_train))\n",
    "      if self.normalized:\n",
    "        new_x_sample.append(self.x_train.values[rand_index])\n",
    "        new_y_sample.append(self.y_train.values[rand_index])\n",
    "      else:\n",
    "        new_x_sample.append(self.x_train.values[rand_index])\n",
    "        new_y_sample.append(self.y_train.values[rand_index])\n",
    "\n",
    "    self.X_samples.append(new_x_sample)\n",
    "    self.Y_samples.append(new_y_sample)\n",
    "\n",
    "  def display(self):\n",
    "    for i in range(len(self.X_samples)):\n",
    "      print(f\"Sample {i} : {self.X_samples[i]}\")\n",
    "\n",
    "  def apply_clasifiers(self):\n",
    "    print(\"Apply clasifiers\")\n",
    "    for i in range(len(self.X_samples)):\n",
    "      current_clasifier = self.clasifiers[np.random.randint(len(self.clasifiers))]\n",
    "      current_clasifier.fit(self.X_samples[i], self.Y_samples[i])\n",
    "      \n",
    "      self.trained_clasifiers.append(current_clasifier)\n",
    "      self.trained_clasifiers[i].fit(self.X_samples[i], self.Y_samples[i])\n",
    "      \n",
    "      if self.normalized:\n",
    "        self.Y_predicts.append(self.trained_clasifiers[i].predict(self.X_test_norm))\n",
    "      else:\n",
    "        self.Y_predicts.append(self.trained_clasifiers[i].predict(self.x_test))\n",
    "\n",
    "  def aggregating(self):\n",
    "    print(\"Aggregating\")\n",
    "    \n",
    "    self.Y_aggregated_predicts = np.apply_along_axis(lambda x: np.bincount(x).argmax(), 0, self.Y_predicts)\n",
    "    print(np.shape(self.Y_aggregated_predicts))\n",
    "\n",
    "  def train(self):\n",
    "    self.apply_clasifiers()\n",
    "    self.aggregating()\n",
    "\n",
    "  def predict(self, x_test):\n",
    "    print(f\"Predict {x_test}\")\n",
    "\n",
    "  def evaluate(self):\n",
    "    print(\"Evaluation\")\n",
    "    evaluate(self.Y_aggregated_predicts, self.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6806,
     "status": "ok",
     "timestamp": 1676065852609,
     "user": {
      "displayName": "Dead-Memories",
      "userId": "15727796903014510038"
     },
     "user_tz": -60
    },
    "id": "N_Z2OeRDZchN",
    "outputId": "031f58a1-c808-40ff-e23a-8e220c61525f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply clasifiers\n",
      "Aggregating\n",
      "(50,)\n",
      "Evaluation\n",
      "Start evaluation\n",
      "General Accuracy 80.0% \n",
      "y pred : (50,), [1 2 3]\n",
      "y test : (50, 1), [1 2 3]\n",
      "[[17  0  0]\n",
      " [ 2 12  5]\n",
      " [ 1  2 11]]\n",
      "F1 score : [0.91891892 0.72727273 0.73333333]\n",
      "Precision : [0.85       0.85714286 0.6875    ]\n",
      "Rappel : [1.         0.63157895 0.78571429]\n"
     ]
    }
   ],
   "source": [
    "bags = Bagging(X, y, nb_sample=15)\n",
    "# bags.display()\n",
    "bags.train()\n",
    "bags.evaluate()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN45WHQO+bTrQ1Klh5bGwUQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
